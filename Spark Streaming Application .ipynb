{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.3.0 pyspark-shell'\n",
    "\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pymongo\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "import Geohash\n",
    "\n",
    "def process_stream(iter):\n",
    "    json_data_list = []\n",
    "    sender_id_list = []\n",
    "    client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "    db = client[\"streamingDataDB\"]\n",
    "    streams = db[\"streams\"]\n",
    "    input_stream = iter.collect()\n",
    "    for data in input_stream:\n",
    "                   \n",
    "        data_str = json.loads(data[1])\n",
    "        data_str = data_str.replace(\"'\",\"\\\"\")\n",
    "        data_json = json.loads(data_str)\n",
    "\n",
    "        json_data_list.append(data_json)\n",
    "        \n",
    "    for json_data in json_data_list:\n",
    "        sender_id_list.append(json_data[\"sender_id\"])\n",
    "    \n",
    "    #print(\"Producer ID in RDD \",sender_id_list)\n",
    "    \n",
    "    \n",
    "    if \"P01\" in sender_id_list:\n",
    "              \n",
    "        #case1: when data is received only from station\n",
    "        if len(set(sender_id_list)) == 1:\n",
    "            #print(\"-----CASE 1------\")\n",
    "\n",
    "            #iterating again to insert climate data sent from station(producer 1)\n",
    "            for json_data in json_data_list:\n",
    "                json_data[\"satellite_data\"] = []\n",
    "                streams.insert_one(json_data)           \n",
    "            \n",
    "        #case2: when data is received from station and either of the satellite\n",
    "        if len(set(sender_id_list)) == 2:\n",
    "            \n",
    "            #print(\"-----CASE 2------\")\n",
    "            \n",
    "            #seperating station and satellite json data and storing it in two lists\n",
    "            \n",
    "            json_data_station_list = []\n",
    "            json_data_satellite_list = []\n",
    "            \n",
    "            for json_data in json_data_list:\n",
    "                if json_data[\"sender_id\"] == \"P01\":\n",
    "                    json_data_station_list.append(json_data)\n",
    "                else:\n",
    "                    json_data_satellite_list.append(json_data)\n",
    "            \n",
    "            #print(\"Station list-----\",json_data_station_list)\n",
    "            #print(\"Satellite list-----\",json_data_satellite_list)\n",
    "            \n",
    "            \n",
    "            #iterating again to join station and satellite streams if they are close to each other\n",
    "            \n",
    "            for json_data_station in json_data_station_list:\n",
    "                json_data_station[\"satellite_data\"] = []\n",
    "                for json_data_satellite in json_data_satellite_list:   \n",
    "                    \n",
    "                    station_hash = Geohash.encode(float(json_data_station[\"latitude\"]),float(json_data_station[\"longitude\"]),precision = 5)\n",
    "                    satellite_hash = Geohash.encode(float(json_data_satellite[\"latitude\"]),float(json_data_satellite[\"longitude\"]),precision = 5)                    \n",
    "                    \n",
    "                    if(station_hash == satellite_hash):\n",
    "                        #print(\"-------HASH EQUAL-------\")\n",
    "                        json_data_station[\"satellite_data\"].append(json_data_satellite)\n",
    "                #print(\"-----FINAL STATION DATA---\",json_data_station)\n",
    "                streams.insert_one(json_data_station)\n",
    "            \n",
    "        #case3: when data is received from station and both satellites\n",
    "        \n",
    "        if len(set(sender_id_list)) == 3:\n",
    "            \n",
    "            #print(\"-----CASE 3------\")\n",
    "            #seperating station and satellite json data and storing it their separate lists\n",
    "            \n",
    "            json_data_station_list = []\n",
    "            json_data_satellite_aqua_list = []\n",
    "            json_data_satellite_terra_list = []\n",
    "            \n",
    "            for json_data in json_data_list:\n",
    "                if json_data[\"sender_id\"] == \"P01\":\n",
    "                    json_data_station_list.append(json_data)\n",
    "                elif json_data[\"sender_id\"] == \"P02\":\n",
    "                    json_data_satellite_aqua_list.append(json_data)\n",
    "                elif json_data[\"sender_id\"] == \"P03\":\n",
    "                    json_data_satellite_terra_list.append(json_data)\n",
    "            \n",
    "            \n",
    "            #generating combined satellite list\n",
    "                                \n",
    "            #print(\"Station list-----\",json_data_station_list)\n",
    "            #print(\"Satellite AQUA list-----\",json_data_satellite_aqua_list)\n",
    "            #print(\"Satellite TERRA list-----\",json_data_satellite_terra_list)\n",
    "            \n",
    "            list_terra_match = []\n",
    "            list_aqua_terra_combined = []\n",
    "            \n",
    "            for index_aqua in range(len(json_data_satellite_aqua_list)):\n",
    "                match_counter = 1\n",
    "                for index_terra in range(len(json_data_satellite_terra_list)):\n",
    "                    aqua_element = json_data_satellite_aqua_list[index_aqua]\n",
    "                    terra_element = json_data_satellite_terra_list[index_terra]\n",
    "                    \n",
    "                    aqua_hash = Geohash.encode(float(aqua_element[\"latitude\"]),float(aqua_element[\"longitude\"]),precision = 5)\n",
    "                    terra_hash = Geohash.encode(float(terra_element[\"latitude\"]),float(terra_element[\"longitude\"]),precision = 5)                    \n",
    "                    \n",
    "                    if(aqua_hash == terra_hash):\n",
    "                        #print(\"SATELLITE HASH MATCHED---\")\n",
    "                        aqua_element[\"surface_temperature_celcius\"] = str((match_counter * int(aqua_element[\"surface_temperature_celcius\"]) + int(terra_element[\"surface_temperature_celcius\"]))//(match_counter + 1))\n",
    "                        aqua_element[\"confidence\"] = str((match_counter * int(aqua_element[\"confidence\"]) + int(terra_element[\"confidence\"]))//(match_counter + 1))\n",
    "                        \n",
    "                        match_counter = match_counter + 1\n",
    "                        \n",
    "                        list_terra_match.append(index_terra)\n",
    "                    \n",
    "                list_aqua_terra_combined.append(aqua_element)\n",
    "                \n",
    "                \n",
    "            #checking for unmatched json data in terra json list and adding it to the combined list\n",
    "            for index_terra in range(len(json_data_satellite_terra_list)):\n",
    "                if index_terra not in list_terra_match:\n",
    "                    list_aqua_terra_combined.append(json_data_satellite_terra_list[index_terra])\n",
    "                                                                        \n",
    "            #print(\"TERRA MATCH LIST--\",  list_terra_match)   \n",
    "            #print(\"MERGED LIST--\",  list_aqua_terra_combined)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #iterating again to join station and combined satellite streams if they are close to each other\n",
    "            \n",
    "            for json_data_station in json_data_station_list:\n",
    "                json_data_station[\"satellite_data\"] = []\n",
    "                for json_data_satellite in list_aqua_terra_combined:                       \n",
    "                    station_hash = Geohash.encode(float(json_data_station[\"latitude\"]),float(json_data_station[\"longitude\"]),precision = 5)\n",
    "                    satellite_hash = Geohash.encode(float(json_data_satellite[\"latitude\"]),float(json_data_satellite[\"longitude\"]),precision = 5)                    \n",
    "\n",
    "                    if(station_hash == satellite_hash):\n",
    "                        #print(\"-------HASH EQUAL-------\")\n",
    "                        json_data_station[\"satellite_data\"].append(json_data_satellite)\n",
    "                #print(\"-----FINAL STATION DATA---\",json_data_station)\n",
    "                streams.insert_one(json_data_station)\n",
    "                                                                             \n",
    "    \n",
    "         \n",
    "n_secs = 10\n",
    "topic = \"AssignmentTaskC\"\n",
    "\n",
    "conf = SparkConf().setAppName(\"KafkaStreamProcessor\").setMaster(\"local[2]\")\n",
    "sc = SparkContext.getOrCreate()\n",
    "if sc is None:\n",
    "    sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"WARN\")\n",
    "ssc = StreamingContext(sc, n_secs)\n",
    "    \n",
    "kafkaStream = KafkaUtils.createDirectStream(ssc, [topic], {\n",
    "                        'bootstrap.servers':'127.0.0.1:9092', \n",
    "                        'group.id':'taskc-group', \n",
    "                        'fetch.message.max.bytes':'15728640',\n",
    "                        'auto.offset.reset':'largest'})\n",
    "                        # Group ID is completely arbitrary\n",
    "\n",
    "\n",
    "lines = kafkaStream.foreachRDD(process_stream)\n",
    "\n",
    "\n",
    "ssc.start()\n",
    "time.sleep(600) # Run stream for 10 minutes just in case no detection of producer\n",
    "ssc.stop(stopSparkContext=True,stopGraceFully=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
